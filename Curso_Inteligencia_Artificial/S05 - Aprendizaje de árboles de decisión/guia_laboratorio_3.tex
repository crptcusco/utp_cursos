\documentclass[12pt]{article}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{float}
\geometry{a4paper, margin=1in}

\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection}{1em}{}

\title{Guía de Laboratorio - Semana 5: Árboles de Decisión}
\author{Inteligencia Artificial (100000S14F) \\ Ingeniería de Software \\ Ciclo 2 Agosto 2025}
\date{\today}

% Configuración para código Python
\lstset{
    language=Python,
    backgroundcolor=\color{white},
    basicstyle=\footnotesize\ttfamily,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=10pt,
    tabsize=4,
    showspaces=false,
    showstringspaces=false,
    frame=single,
    breaklines=true,
    captionpos=b,
    breakatwhitespace=false
}

\begin{document}

\maketitle

\section{Objetivos de la Sesión}
Al finalizar esta sesión de laboratorio, el estudiante será capaz de:
\begin{itemize}
    \item Comprender los fundamentos teóricos y matemáticos de los árboles de decisión
    \item Implementar un árbol de decisión utilizando scikit-learn con diversas configuraciones
    \item Realizar preprocesamiento de datos adecuado para modelos de árboles de decisión
    \item Evaluar el rendimiento del modelo utilizando múltiples métricas
    \item Visualizar e interpretar la estructura del árbol de decisión
    \item Optimizar hiperparámetros mediante validación cruzada
    \item Aplicar técnicas para evitar sobreajuste (overfitting)
\end{itemize}

\section{Marco Teórico}

Los árboles de decisión son estructuras jerárquicas utilizadas para clasificación y regresión. Constan de:

\begin{itemize}
    \item \textbf{Nodos raíz e internos}: Representan pruebas sobre atributos
    \item \textbf{Ramas}: Resultados posibles de las pruebas
    \item \textbf{Nodos hoja}: Decisiones finales (clases o valores)
\end{itemize}

\subsection{Algoritmos de Construcción}

El algoritmo ID3 (Iterative Dichotomiser 3) utiliza la \textbf{ganancia de información} basada en la \textbf{entropía}:

\begin{equation}
\text{Entropía: } H(S) = -\sum_{i=1}^{c} p_i \log_2 p_i
\end{equation}

\begin{equation}
\text{Ganancia de información: } IG(S, A) = H(S) - \sum_{t \in T} p(t) H(t)
\end{equation}

El algoritmo C4.5 (extensión de ID3) utiliza la \textbf{ganancia de razón}:

\begin{equation}
\text{Ganancia de razón: } GR(S, A) = \frac{IG(S, A)}{H(A)}
\end{equation}

El algoritmo CART utiliza el \textbf{índice Gini}:

\begin{equation}
\text{Índice Gini: } Gini(S) = 1 - \sum_{i=1}^{c} p_i^2
\end{equation}

\section{Configuración del Entorno}

\subsection{Requisitos Previos}
\begin{lstlisting}
# Instalar las bibliotecas necesarias
pip install scikit-learn==1.2.2 pandas==2.0.1 matplotlib==3.7.1 numpy==1.24.3 graphviz==0.20.1
\end{lstlisting}

\subsection{Configuración de Entorno de Desarrollo}
Recomendamos utilizar Jupyter Notebook o Google Colab para este laboratorio. Para configurar el entorno:

\begin{lstlisting}
# Crear un entorno virtual (opcional pero recomendado)
python -m venv arboles_decision
source arboles_decision/bin/activate  # Linux/Mac
# o
.\arboles_decision\Scripts\activate  # Windows

# Instalar paquetes
pip install -r requirements.txt
\end{lstlisting}

\section{Implementación Paso a Paso}

\subsection{Paso 1: Importar Bibliotecas}
\begin{lstlisting}
# Bibliotecas fundamentales
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import Image, display

# Scikit-learn para árboles de decisión
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier, export_graphviz, plot_tree
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, 
                             precision_score, recall_score, f1_score, roc_curve, auc)
from sklearn.preprocessing import label_binarize
from sklearn.utils import resample

# Graphviz para visualización
import graphviz

# Configuración de estilo
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")
%matplotlib inline
\end{lstlisting}

\subsection{Paso 2: Cargar y Explorar Datos}
\begin{lstlisting}
# Cargar dataset
iris = load_iris()
X = iris.data
y = iris.target

# Crear DataFrame para mejor visualización
df = pd.DataFrame(X, columns=iris.feature_names)
df['target'] = y
df['species'] = df['target'].apply(lambda x: iris.target_names[x])

print("=== INFORMACIÓN DEL DATASET IRIS ===")
print(f"Dimensiones: {X.shape}")
print(f"Características: {iris.feature_names}")
print(f"Clases: {iris.target_names}")

print("\n=== PRIMERAS FILAS ===")
print(df.head())

print("\n=== ESTADÍSTICAS DESCRIPTIVAS ===")
print(df.describe())

print("\n=== DISTRIBUCIÓN DE CLASES ===")
print(df['species'].value_counts())

# Visualización de distribuciones
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
for i, feature in enumerate(iris.feature_names):
    row, col = i // 2, i % 2
    for species in iris.target_names:
        species_data = df[df['species'] == species][feature]
        axes[row, col].hist(species_data, alpha=0.7, label=species)
    axes[row, col].set_title(f'Distribución de {feature}')
    axes[row, col].set_xlabel(feature)
    axes[row, col].set_ylabel('Frecuencia')
    axes[row, col].legend()

plt.tight_layout()
plt.savefig('distribuciones_caracteristicas.png', dpi=300, bbox_inches='tight')
plt.show()

# Matriz de correlación
plt.figure(figsize=(10, 8))
correlation_matrix = df[iris.feature_names].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Matriz de Correlación de Características')
plt.savefig('matriz_correlacion.png', dpi=300, bbox_inches='tight')
plt.show()
\end{lstlisting}

\subsection{Paso 3: Preprocesamiento de Datos}
\begin{lstlisting}
# Dividir en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.3, 
    random_state=42, 
    stratify=y,  # Mantener proporción de clases
    shuffle=True
)

print(f"Tamaño conjunto de entrenamiento: {X_train.shape}")
print(f"Tamaño conjunto de prueba: {X_test.shape}")

# Verificar distribución de clases en ambos conjuntos
print("\nDistribución en entrenamiento:")
unique_train, counts_train = np.unique(y_train, return_counts=True)
for cls, count in zip(unique_train, counts_train):
    print(f"Clase {iris.target_names[cls]}: {count} muestras ({count/len(y_train)*100:.2f}%)")

print("\nDistribución en prueba:")
unique_test, counts_test = np.unique(y_test, return_counts=True)
for cls, count in zip(unique_test, counts_test):
    print(f"Clase {iris.target_names[cls]}: {count} muestras ({count/len(y_test)*100:.2f}%)")
\end{lstlisting}

\subsection{Paso 4: Crear y Entrenar el Modelo}
\begin{lstlisting}
# Configuración de hiperparámetros
parametros_arbol = {
    'criterion': 'entropy',       # Criterio de división: 'gini' o 'entropy'
    'max_depth': 3,               # Profundidad máxima del árbol
    'min_samples_split': 2,       # Mínimo de muestras para dividir un nodo
    'min_samples_leaf': 1,        # Mínimo de muestras en un nodo hoja
    'max_features': None,         # Número de características a considerar
    'random_state': 42,           # Semilla para reproducibilidad
    'ccp_alpha': 0.0,             # Parámetro de podado cost-complexity
    'class_weight': None          # Pesos de clases (útil para datasets desbalanceados)
}

# Crear el clasificador de árbol de decisión
clf = DecisionTreeClassifier(**parametros_arbol)

# Entrenar el modelo
clf.fit(X_train, y_train)

# Hacer predicciones
y_pred = clf.predict(X_test)
y_pred_proba = clf.predict_proba(X_test)  # Probabilidades para cada clase

# Mostrar información del árbol resultante
print("=== INFORMACIÓN DEL ÁRBOL ===")
print(f"Número de nodos: {clf.tree_.node_count}")
print(f"Profundidad del árbol: {clf.get_depth()}")
print(f"Número de hojas: {clf.get_n_leaves()}")
\end{lstlisting}

\subsection{Paso 5: Evaluar el Modelo}
\begin{lstlisting}
# Calcular métricas de evaluación
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print("=== MÉTRICAS DE EVALUACIÓN ===")
print(f"Precisión (Accuracy): {accuracy:.4f}")
print(f"Precisión (Precision): {precision:.4f}")
print(f"Sensibilidad (Recall): {recall:.4f}")
print(f"Puntuación F1: {f1:.4f}")

# Matriz de confusión
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=iris.target_names, 
            yticklabels=iris.target_names)
plt.title('Matriz de Confusión')
plt.ylabel('Etiqueta Real')
plt.xlabel('Etiqueta Predicha')
plt.savefig('matriz_confusion.png', dpi=300, bbox_inches='tight')
plt.show()

# Reporte de clasificación detallado
print("\n=== REPORTE DE CLASIFICACIÓN ===")
print(classification_report(y_test, y_pred, target_names=iris.target_names))

# Curvas ROC (para clasificación multiclase)
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
n_classes = y_test_bin.shape[1]

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot all ROC curves
plt.figure(figsize=(10, 8))
colors = ['aqua', 'darkorange', 'cornflowerblue']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label='ROC curve of class {0} (area = {1:0.2f})'
             ''.format(iris.target_names[i], roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curvas ROC para Clasificación Multiclase')
plt.legend(loc="lower right")
plt.savefig('curvas_roc.png', dpi=300, bbox_inches='tight')
plt.show()
\end{lstlisting}

\subsection{Paso 6: Visualizar el Árbol de Decisión}
\begin{lstlisting}
# Visualización con Graphviz (alta calidad)
dot_data = export_graphviz(
    clf,
    out_file=None,
    feature_names=iris.feature_names,
    class_names=iris.target_names,
    filled=True,           # Nodos coloreados
    rounded=True,          # Bordes redondeados
    special_characters=True,
    proportion=True,       # Mostrar proporciones en lugar de counts
    impurity=True,         # Mostrar impureza
    node_ids=True          # Mostrar IDs de nodos
)

graph = graphviz.Source(dot_data)
graph.format = 'png'
graph.render('arbol_decision_iris', view=False, cleanup=True)

# Visualización con matplotlib (más simple pero interactiva)
plt.figure(figsize=(20, 12))
plot_tree(clf, 
          feature_names=iris.feature_names, 
          class_names=iris.target_names, 
          filled=True, 
          rounded=True, 
          fontsize=10)
plt.title("Árbol de Decisión - Dataset Iris")
plt.savefig('arbol_decision_matplotlib.png', dpi=300, bbox_inches='tight')
plt.show()

# Mostrar importancia de características
importances = clf.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 6))
plt.title("Importancia de las Características")
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), [iris.feature_names[i] for i in indices])
plt.xlim([-1, X.shape[1]])
plt.tight_layout()
plt.savefig('importancia_caracteristicas.png', dpi=300, bbox_inches='tight')
plt.show()

print("Importancia de características:")
for i, idx in enumerate(indices):
    print(f"{i+1}. {iris.feature_names[idx]}: {importances[idx]:.4f}")
\end{lstlisting}

\section{Experimentación con Hiperparámetros}

\subsection{Análisis de Profundidad del Árbol}
\begin{lstlisting}
# Probar diferentes profundidades máximas
profundidades = range(1, 21)
train_scores = []
test_scores = []
cv_scores = []

for profundidad in profundidades:
    # Crear y entrenar modelo
    clf_temp = DecisionTreeClassifier(max_depth=profundidad, random_state=42)
    clf_temp.fit(X_train, y_train)
    
    # Calcular precisión en entrenamiento y prueba
    train_score = clf_temp.score(X_train, y_train)
    test_score = clf_temp.score(X_test, y_test)
    
    # Calcular validación cruzada
    cv_score = cross_val_score(clf_temp, X, y, cv=5).mean()
    
    train_scores.append(train_score)
    test_scores.append(test_score)
    cv_scores.append(cv_score)
    
    print(f"Profundidad: {profundidad:2d} | Train: {train_score:.4f} | Test: {test_score:.4f} | CV: {cv_score:.4f}")

# Graficar resultados
plt.figure(figsize=(12, 6))
plt.plot(profundidades, train_scores, 'o-', label='Precisión en Entrenamiento')
plt.plot(profundidades, test_scores, 'o-', label='Precisión en Prueba')
plt.plot(profundidades, cv_scores, 'o-', label='Validación Cruzada (5-fold)')
plt.xlabel('Profundidad Máxima del Árbol')
plt.ylabel('Precisión')
plt.title('Efecto de la Profundidad del Árbol en el Rendimiento')
plt.legend()
plt.grid(True)
plt.savefig('profundidad_vs_rendimiento.png', dpi=300, bbox_inches='tight')
plt.show()
\end{lstlisting}

\subsection{Optimización de Hiperparámetros con Grid Search}
\begin{lstlisting}
# Definir espacio de búsqueda de hiperparámetros
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [3, 5, 7, 10, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5],
    'max_features': [None, 'sqrt', 'log2'],
    'ccp_alpha': [0.0, 0.01, 0.1]  # Parámetro de podado
}

# Crear el modelo base
dt = DecisionTreeClassifier(random_state=42)

# Configurar la búsqueda en grid
grid_search = GridSearchCV(
    estimator=dt,
    param_grid=param_grid,
    scoring='accuracy',
    cv=5,           # Validación cruzada de 5 folds
    n_jobs=-1,      # Usar todos los cores disponibles
    verbose=1       # Mostrar progreso
)

# Ejecutar la búsqueda en grid
grid_search.fit(X_train, y_train)

# Mejores parámetros y resultados
print("Mejores parámetros encontrados:")
print(grid_search.best_params_)
print(f"\nMejor precisión en validación cruzada: {grid_search.best_score_:.4f}")

# Evaluar el mejor modelo en el conjunto de prueba
best_clf = grid_search.best_estimator_
y_pred_best = best_clf.predict(X_test)
best_accuracy = accuracy_score(y_test, y_pred_best)
print(f"Precisión del mejor modelo en prueba: {best_accuracy:.4f}")

# Comparar con el modelo inicial
print(f"Mejora respecto al modelo inicial: {(best_accuracy - accuracy):.4f}")

# Visualizar el mejor árbol
plt.figure(figsize=(20, 12))
plot_tree(best_clf, 
          feature_names=iris.feature_names, 
          class_names=iris.target_names, 
          filled=True, 
          rounded=True, 
          fontsize=10)
plt.title("Mejor Árbol de Decisión después de la Optimización")
plt.savefig('mejor_arbol_decision.png', dpi=300, bbox_inches='tight')
plt.show()
\end{lstlisting}

\section{Ejercicios Prácticos}

\subsection{Ejercicio 1: Análisis de Importancia de Características}
\begin{enumerate}
    \item Extrae la importancia de cada característica del modelo entrenado
    \item Visualiza la importancia de características en un gráfico de barras horizontal
    \item Interpreta qué características son más relevantes para la clasificación
    \item Compara los resultados con la matriz de correlación generada anteriormente
\end{enumerate}

\textbf{Solución:}
\begin{lstlisting}
# Obtener importancia de características
importances = best_clf.feature_importances_
feature_names = iris.feature_names

# Crear DataFrame para mejor visualización
importance_df = pd.DataFrame({
    'Característica': feature_names,
    'Importancia': importances
}).sort_values('Importancia', ascending=True)

# Gráfico de barras horizontal
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Característica'], importance_df['Importancia'])
plt.xlabel('Importancia')
plt.title('Importancia de Características en el Mejor Modelo')
for i, v in enumerate(importance_df['Importancia']):
    plt.text(v + 0.001, i, f'{v:.4f}', va='center')
plt.tight_layout()
plt.savefig('importancia_caracteristicas_mejor_modelo.png', dpi=300, bbox_inches='tight')
plt.show()

# Análisis
print("Análisis de importancia de características:")
for i, row in importance_df.iterrows():
    print(f"- {row['Característica']}: {row['Importancia']:.4f}")
\end{lstlisting}

\subsection{Ejercicio 2: Validación Cruzada y Estabilidad del Modelo}
\begin{enumerate}
    \item Realiza validación cruzada con diferentes semillas aleatorias
    \item Evalúa la estabilidad del modelo con diferentes divisiones de datos
    \item Calcula intervalos de confianza para la precisión del modelo
\end{enumerate}

\textbf{Solución:}
\begin{lstlisting}
# Validación cruzada con diferentes semillas
n_iterations = 10
cv_scores = []

for i in range(n_iterations):
    # Crear modelo con diferentes semillas
    clf_cv = DecisionTreeClassifier(**grid_search.best_params_)
    clf_cv.random_state = i  # Cambiar semilla
    
    # Realizar validación cruzada
    scores = cross_val_score(clf_cv, X, y, cv=5, scoring='accuracy')
    cv_scores.append(scores.mean())
    print(f"Iteración {i+1}: Precisión CV = {scores.mean():.4f}")

# Calcular estadísticas
mean_accuracy = np.mean(cv_scores)
std_accuracy = np.std(cv_scores)
confidence_interval = 1.96 * std_accuracy / np.sqrt(n_iterations)  # 95% IC

print(f"\nPrecisión media: {mean_accuracy:.4f}")
print(f"Desviación estándar: {std_accuracy:.4f}")
print(f"Intervalo de confianza (95%): ({mean_accuracy - confidence_interval:.4f}, {mean_accuracy + confidence_interval:.4f})")

# Visualizar distribución de precisiones
plt.figure(figsize=(10, 6))
plt.hist(cv_scores, bins=10, edgecolor='black', alpha=0.7)
plt.axvline(mean_accuracy, color='red', linestyle='--', label=f'Media: {mean_accuracy:.4f}')
plt.xlabel('Precisión')
plt.ylabel('Frecuencia')
plt.title('Distribución de Precisiones en Validación Cruzada')
plt.legend()
plt.savefig('distribucion_precision_cv.png', dpi=300, bbox_inches='tight')
plt.show()
\end{lstlisting}

\subsection{Ejercicio 3: Aplicación a un Dataset Diferente}
\begin{enumerate}
    \item Carga el dataset de cáncer de mama de scikit-learn
    \item Aplica el mismo proceso de preprocesamiento y modelado
    \item Compara los resultados con los obtenidos con el dataset Iris
\end{enumerate}

\textbf{Solución:}
\begin{lstlisting}
from sklearn.datasets import load_breast_cancer

# Cargar dataset de cáncer de mama
cancer = load_breast_cancer()
X_cancer = cancer.data
y_cancer = cancer.target

print(f"Dataset de cáncer de mama: {X_cancer.shape}")
print(f"Características: {cancer.feature_names}")
print(f"Clases: {cancer.target_names}")

# Preprocesamiento (escalado recomendado para este dataset)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_cancer_scaled = scaler.fit_transform(X_cancer)

# División en train/test
X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(
    X_cancer_scaled, y_cancer, test_size=0.3, random_state=42, stratify=y_cancer
)

# Entrenar modelo con mejores parámetros del ejercicio anterior
clf_cancer = DecisionTreeClassifier(**grid_search.best_params_)
clf_cancer.fit(X_train_c, y_train_c)

# Evaluar
y_pred_c = clf_cancer.predict(X_test_c)
accuracy_c = accuracy_score(y_test_c, y_pred_c)
print(f"Precisión en dataset de cáncer de mama: {accuracy_c:.4f}")

# Comparar con modelo básico
clf_basic = DecisionTreeClassifier(random_state=42)
clf_basic.fit(X_train_c, y_train_c)
y_pred_basic = clf_basic.predict(X_test_c)
accuracy_basic = accuracy_score(y_test_c, y_pred_basic)
print(f"Precisión con modelo básico: {accuracy_basic:.4f}")
print(f"Mejora con parámetros optimizados: {accuracy_c - accuracy_basic:.4f}")
\end{lstlisting}

\section{Recursos Adicionales}

\subsection{Bibliografía Recomendada}
\begin{itemize}
    \item Mitchell, T. M. (1997). \textit{Machine Learning}. McGraw-Hill. (Capítulo 3)
    \item Hastie, T., Tibshirani, R., \& Friedman, J. (2009). \textit{The Elements of Statistical Learning}. Springer. (Capítulo 9)
    \item Géron, A. (2019). \textit{Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow}. O'Reilly. (Capítulo 6)
\end{itemize}

\subsection{Enlaces Útiles}
\begin{itemize}
    \item Documentación de scikit-learn: \url{https://scikit-learn.org/stable/modules/tree.html}
    \item Tutorial interactivo de árboles de decisión: \url{https://www.datacamp.com/community/tutorials/decision-tree-classification-python}
    \item Visualización interactiva de árboles de decisión: \url{http://www.r2d3.us/visual-intro-to-machine-learning-part-1/}
    \item Repositorio de datasets para práctica: \url{https://archive.ics.uci.edu/ml/index.php}
\end{itemize}

\subsection{Herramientas Alternativas}
\begin{itemize}
    \item WEKA: Herramienta gráfica para minería de datos
    \item RapidMiner: Plataforma de ciencia de datos con interfaz visual
    \item KNIME: Plataforma de analítica de datos de código abierto
\end{itemize}

\end{document}
